<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Writing Under Surveillance: The Problem with AI Detection ‚Äî Zach Muhlbauer</title>
  <meta name="description" content="The problem with AI detection software and its disproportionate harm to multilingual, working-class, and neurodivergent students.">
  <style>
    :root {
      --bg: #0e0e0e;
      --surface: #161616;
      --border: #2a2a2a;
      --text: #d4d0c8;
      --muted: #888;
      --accent: #c8a97e;
      --link: #8ab4c8;
      --max: 680px;
    }

    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      background: var(--bg);
      color: var(--text);
      font-family: 'Georgia', 'Times New Roman', serif;
      font-size: 18px;
      line-height: 1.75;
      min-height: 100vh;
      padding: 0 1.5rem;
    }

    .wrap {
      max-width: var(--max);
      margin: 0 auto;
      padding: 4rem 0 6rem;
    }

    .back {
      display: inline-block;
      font-family: 'Helvetica Neue', sans-serif;
      font-size: 13px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--muted);
      text-decoration: none;
      margin-bottom: 3rem;
      transition: color 0.2s;
    }
    .back:hover { color: var(--accent); }
    .back::before { content: '‚Üê '; }

    header { margin-bottom: 3rem; border-bottom: 1px solid var(--border); padding-bottom: 2rem; }

    h1 {
      font-size: 2rem;
      line-height: 1.25;
      font-weight: normal;
      color: #f0ece0;
      margin-bottom: 0.75rem;
      letter-spacing: -0.01em;
    }

    .byline {
      font-family: 'Helvetica Neue', sans-serif;
      font-size: 14px;
      color: var(--muted);
      letter-spacing: 0.04em;
    }

    .byline .author { color: var(--accent); }

    .badge {
      display: inline-block;
      margin-left: 0.75rem;
      font-size: 11px;
      letter-spacing: 0.1em;
      text-transform: uppercase;
      background: var(--surface);
      border: 1px solid var(--border);
      color: var(--muted);
      padding: 2px 8px;
      border-radius: 3px;
      vertical-align: middle;
    }

    article p {
      margin-bottom: 1.5rem;
      color: var(--text);
    }

    article em { font-style: italic; color: #c8c0b0; }

    cite {
      font-style: normal;
      color: var(--muted);
      font-size: 0.9em;
    }

    .pullquote {
      border-left: 3px solid var(--accent);
      margin: 2.5rem 0;
      padding: 0.5rem 1.5rem;
      color: #c8c0b0;
      font-size: 1.1em;
      line-height: 1.6;
    }

    .works-cited {
      margin-top: 4rem;
      padding-top: 2rem;
      border-top: 1px solid var(--border);
    }

    .works-cited h2 {
      font-family: 'Helvetica Neue', sans-serif;
      font-size: 13px;
      letter-spacing: 0.12em;
      text-transform: uppercase;
      color: var(--muted);
      font-weight: normal;
      margin-bottom: 1.5rem;
    }

    .works-cited ol {
      list-style: none;
      padding: 0;
    }

    .works-cited li {
      font-size: 14px;
      line-height: 1.65;
      color: var(--muted);
      margin-bottom: 0.85rem;
      padding-left: 1.5em;
      text-indent: -1.5em;
    }

    .works-cited a {
      color: var(--link);
      text-decoration: none;
    }
    .works-cited a:hover { text-decoration: underline; }

    .revision-tag {
      display: inline-block;
      font-family: 'Helvetica Neue', sans-serif;
      font-size: 11px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--muted);
      background: var(--surface);
      border: 1px solid var(--border);
      padding: 3px 8px;
      border-radius: 3px;
      margin-top: 2rem;
    }

    @media (max-width: 600px) {
      body { font-size: 16px; }
      h1 { font-size: 1.5rem; }
    }
  </style>
</head>
<body>
  <div class="wrap">
    <a href="/quimbot/" class="back">Gallery</a>

    <header>
      <h1>Writing Under Surveillance: The Problem with AI Detection</h1>
      <p class="byline">
        <span class="author">Zach Muhlbauer</span>
        <span class="badge">Draft v3 ¬∑ Feb 2026</span>
      </p>
    </header>

    <article>
      <div class="pullquote">
        "There has always been resistance to teaching machines and to the technocracy in which they are embedded... And perhaps it's worth repeating that that resistance did not come only from disgruntled educators."
        <br><cite>‚Äî Audrey Watters, <em>Teaching Machines</em></cite>
      </div>

      <p>CUNY students certainly know the feeling. On Reddit, they describe anxiety and frustration at the prospect of being falsely accused by widely discredited software, their professors deferring to opaque algorithmic systems over their own judgement or the testimony of their students.</p>

      <p>AI detection software has already begun to shape how students learn to write and under what conditions they see themselves as writers. While multilingual students report being accused of cheating because their syntax looks "too clean," others describe misspelling words and punctuating incorrectly to evade a false positive designation and a failing grade to go with it, though every word is their own.</p>

      <p>When students feel compelled to stage their own humanity for an audience of AI detectors, they write not for humans but for algorithmic systems that are sparsely understood by professors who require them or administrators who procure them, inflicting harm that falls hardest on under-resourced, working-class students like so many here at CUNY.</p>

      <p>To understand the problem with AI detection, consider what these services actually claim to measure. For instance, GPTZero relies on two metrics: the first is <em>perplexity</em>, a measure of how well a language model would predict each successive word in a passage; the second is <em>burstiness</em>, which tracks creative variability in sentence rhythm and structure. Such a premise relies on the assumption that human writers naturally exhibit syntactic variance, often mixing long and short sentences together, while AI models tend toward consistent, flat tempos at both the sentence- and paragraph-level. In turn, these algorithmic scores are used to then calculate the probability that a large language model (LLM) produced content submitted by a student <cite>("AI Detectors"; Galczynski)</cite>.</p>

      <p>The premise is shakier than it sounds. A 2025 detector comparison video reports that identical content was labeled 10% AI-generated by one tool and 81% by another <cite>(Engelbrecht)</cite>. It only follows that commercial detectors trained on different datasets, each with distinct labeling standards, would diverge when compared across services. On the flipside people fare no better, with a recent study placing human attempts to classify AI-generated text at a paltry 19% accuracy, which is as good as guesswork <cite>(Cheng et al.)</cite>.</p>

      <p>Detection failures have also been documented at scale. For instance, one of the most comprehensive accounts in the field, published in the <em>International Journal for Educational Integrity</em>, tested twelve publicly available tools alongside Turnitin and PlagiarismCheck, if only to conclude that they were "neither accurate nor reliable," and exhibited a systematic bias toward classifying AI-generated text as human-written rather than detecting it <cite>(Weber-Wulff et al.)</cite>. Scaled up even further, a "low" 1% false positive rate across 22.35 million first-year college essays amounts to 223,500 essays falsely flagged in a single year <cite>(Hirsch)</cite>.</p>

      <p>Mind you, these are not minor calibration errors. As Jordan Galczynski of UCLA's HumTech observes, the rush to adopt detection technology in higher education has produced classification systems that reify and outsource assessment to automated constructs of human authenticity <cite>(Galczynski)</cite>. The MLA-CCCC Joint Task Force on Writing and AI put it plainly in its first working paper: detection tools generate "false accusations" that "may disproportionately affect marginalized groups" <cite>(MLA-CCCC Joint Task Force on Writing and AI)</cite>. This point matters because AI detectors measure not cheating but legibility to an algorithm‚Äîand legibility is not evenly distributed.</p>

      <p>To make matters worse, false positives fall hardest on those already at the margins. A Stanford study of seven widely-used detectors found they classified 61.22% of TOEFL essays by non-native English speakers as AI-generated <cite>(Liang et al.)</cite>. Across all seven detectors, 89 of 91 essays were flagged by at least one tool. The reason is baked into the architecture. Non-native speakers tend to score lower on perplexity, and detectors use perplexity as a proxy for human authorship, penalizing writers whose patterns resemble what AI produces <cite>("AI Detectors Biased Against Non-Native English Writers")</cite>. The same disparity appears along racial lines. Common Sense Media found Black students faced disproportionately higher AI-detection accusations than white students <cite>(Hirsch)</cite>. The same disparity holds for neurodiverse students, who are more likely to be falsely flagged precisely because their writing patterns diverge from the narrow templates these tools treat as authentically human <cite>(Hirsch)</cite>.</p>

      <p>Such conditions resemble a police state of writing where students must answer to the verdicts of unproven algorithmic systems that are painfully easy to game. For instance, running synthetic text through a paraphrasing tool dropped DetectGPT's accuracy from 70.3% to 4.6% without changing meaning <cite>(Krishna et al.)</cite>. Adding a single word like "cheeky" to a text generation prompt was also reported to fool detectors 80‚Äì90% of the time <cite>("AI Detection Tools," USD Law Library)</cite>. In such cases, we are invited to consider why our institutions keep insisting, if not pretending, that AI detection works in the first place?</p>

      <p>No matter their complexity or sophistication, AI detectors seek to classify and identify patterns in language that are neither stable across large language models (LLMs) nor robust to adversarial modification by end users intent on beating the system <cite>(Weber-Wulff et al.)</cite>. They are also anxiety-inducing, highly unpredictable, and bear standards for human writing as opaque as they are normativizing.</p>

      <p>So, then, as LLMs grow more and more capable of mimicking human writing, and the technical distinction between machine and human text becomes harder to sustain, the question follows whether the problem of AI detection itself is sound and worth our concern, or rather intractable and more trouble than it's worth. For my part, I'd hazard a guess to say the latter.</p>

      <p>Where surveillance ends, the real work begins: whether in or around the classroom, in reading each other's work with care and responding to it honestly, or in reminding ourselves that learning is messier in practice than any set of algorithms can name. Detection practices foreclose that work, recasting educators as auditors and their students as suspects, undermining the conditions under which young writers learn, as Paulo Freire puts it, to read the word and the world.</p>

      <p>But trust can be rebuilt, and it so often starts simply, and slowly, with the everyday practice of reading and writing together again.</p>

      <div class="revision-tag">Round 25 ¬∑ MLA-CCCC integrated; cheeky prompt framing fixed; Weber-Wulff count corrected</div>

      <div style="margin-top:2.5rem;padding-top:2rem;border-top:1px solid var(--border)">
        <p style="font-size:0.92em;color:var(--muted);line-height:1.75">AI use in your class may still disrupt learning goals or class community. If so, consider the small wins and tips outlined in this VP companion resource: <a href="teaching-tips.html" style="color:var(--link)">Small Wins &amp; Teaching Tips</a>.</p>
      </div>
    </article>

    <div style="margin-top:3rem;padding:0.85rem 1.25rem;background:var(--surface);border:1px solid var(--border);border-radius:5px;font-family:'Helvetica Neue',sans-serif;font-size:13px;color:var(--muted);line-height:1.8">
      üìã <a href="citations.html" style="color:var(--link);text-decoration:none">Citation Validation</a> ‚Äî Every source verified and annotated. Conducted by Quimbot (N‚ÄìZ) and Petrarch (A‚ÄìM). <a href="citations.html" style="color:var(--muted);text-decoration:none;opacity:0.7">‚Üí View document</a><br>
      üßë‚Äçüè´ <a href="teaching-tips.html" style="color:var(--link);text-decoration:none">Small Wins &amp; Teaching Tips</a> ‚Äî A VP companion resource: assignment makeovers, disclosure policies, analog check-ins, and more. <a href="teaching-tips.html" style="color:var(--muted);text-decoration:none;opacity:0.7">‚Üí View document</a>
    </div>

    <div class="works-cited">
      <h2>Works Cited</h2>
      <ol>
        <li>"AI Detectors." <em>Instructional Resources</em>, Illinois State University, <a href="https://prodev.illinoisstate.edu/instructional-resources/pedagogy/ai/detectors/" target="_blank">prodev.illinoisstate.edu/‚Ä¶</a>. Accessed 5 Feb. 2026.</li>
        <li>"AI Detectors Biased Against Non-Native English Writers." <em>Stanford HAI</em>, Stanford University, <a href="https://hai.stanford.edu/news/ai-detectors-biased-against-non-native-english-writers" target="_blank">hai.stanford.edu/‚Ä¶</a>. Accessed 5 Feb. 2026.</li>
        <li>"AI Detection Tools." <em>USD Law Library Guides</em>, University of San Diego, <a href="https://lawlibguides.sandiego.edu/c.php?g=1443311&p=10721367" target="_blank">lawlibguides.sandiego.edu/‚Ä¶</a>. Accessed 5 Feb. 2026.</li>
        <li>Cheng, Adam, et al. "Ability of AI Detection Tools and Humans to Accurately Identify Different Forms of AI-Generated Written Content." <em>Advances in Simulation</em>, Nov. 2025, <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12752165/" target="_blank">pmc.ncbi.nlm.nih.gov/‚Ä¶</a>. Accessed 5 Feb. 2026.</li>
        <li>Engelbrecht, Leon. "AI Detection Tool Comparison 2025." <em>YouTube</em>, 2025, <a href="https://www.youtube.com/watch?v=N3RtTCF9E8g" target="_blank">youtube.com/‚Ä¶</a>. Accessed 5 Feb. 2026.</li>
        <li>Freire, Paulo, and Donaldo Macedo. <em>Literacy: Reading the Word and the World</em>. Bergin &amp; Garvey, 1987.</li>
        <li>Galczynski, Jordan. "The Imperfection of AI Detection Tools." <em>HumTech</em>, UCLA, 9 Oct. 2025, <a href="https://humtech.ucla.edu/technology/the-imperfection-of-ai-detection-tools/" target="_blank">humtech.ucla.edu/‚Ä¶</a>. Accessed 28 Feb. 2026.</li>
        <li>GPTZero. <em>GPTZero</em>, <a href="https://gptzero.me" target="_blank">gptzero.me</a>. Accessed 5 Feb. 2026.</li>
        <li>Hirsch, Amanda. "AI Detectors: An Ethical Minefield." <em>CITL</em>, Northern Illinois University, 12 Dec. 2024, <a href="https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/" target="_blank">citl.news.niu.edu/‚Ä¶</a>. Accessed 5 Feb. 2026.</li>
        <li>Krishna, Kalpesh, et al. "Paraphrasing Evades Detectors of AI-Generated Text, but Retrieval Is an Effective Defense." <em>NeurIPS 2023</em>, <a href="https://openreview.net/forum?id=WbFhFvjjKj" target="_blank">openreview.net/‚Ä¶</a>. Accessed 5 Feb. 2026.</li>
        <li>Liang, Weixin, et al. "GPT Detectors Are Biased Against Non-Native English Writers." <em>Patterns</em>, vol. 4, no. 7, 2023, <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10382961/" target="_blank">pmc.ncbi.nlm.nih.gov/‚Ä¶</a>.</li>
        <li>MLA-CCCC Joint Task Force on Writing and AI. <em>Overview of the Issues, Statement of Principles, and Recommendations</em>. Working Paper 1, July 2023, <a href="https://aiandwriting.hcommons.org/working-paper-1/" target="_blank">aiandwriting.hcommons.org/‚Ä¶</a>. Accessed 1 Mar. 2026.</li>
        <li>Weber-Wulff, Debora, et al. "Testing of Detection Tools for AI-Generated Text." <em>International Journal for Educational Integrity</em>, vol. 19, no. 1, 2023, <a href="https://eprints.whiterose.ac.uk/id/eprint/207396/" target="_blank">eprints.whiterose.ac.uk/‚Ä¶</a>. Also at <a href="https://arxiv.org/abs/2306.15666" target="_blank">arxiv.org/abs/2306.15666</a>. Accessed 28 Feb. 2026.</li>
        <li>Watters, Audrey. <em>Teaching Machines: The History of Personalized Learning</em>. The MIT Press, 2021.</li>
      </ol>
      <p style="margin-top:1rem;font-size:0.95rem;"><strong>Citation validation log:</strong> <a href="./citations.html">View source-by-source citation validation</a>.</p>
    </div>
  </div>
</body>
</html>
