Initializing Tinker ServiceClient (base_url=https://tinker.thinkingmachines.dev/services/tinker-prod)
✓ ServiceClient initialized
Getting server capabilities...
✓ Available models: ['deepseek-ai/DeepSeek-V3.1', 'deepseek-ai/DeepSeek-V3.1-Base', 'moonshotai/Kimi-K2-Thinking', 'meta-llama/Llama-3.1-70B', 'meta-llama/Llama-3.1-8B', 'meta-llama/Llama-3.1-8B-Instruct', 'meta-llama/Llama-3.2-1B', 'meta-llama/Llama-3.2-3B', 'meta-llama/Llama-3.3-70B-Instruct', 'Qwen/Qwen3-235B-A22B-Instruct-2507', 'Qwen/Qwen3-30B-A3B', 'Qwen/Qwen3-30B-A3B-Base', 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'Qwen/Qwen3-32B', 'Qwen/Qwen3-4B-Instruct-2507', 'Qwen/Qwen3-8B', 'Qwen/Qwen3-8B-Base', 'Qwen/Qwen3-VL-235B-A22B-Instruct', 'Qwen/Qwen3-VL-30B-A3B-Instruct', 'openai/gpt-oss-120b', 'openai/gpt-oss-20b']
✓ Auto-selected base model: Qwen/Qwen3-8B
Creating LoRA training client (rank=16)...
✓ Training client created
Getting tokenizer...
✓ Tokenizer ready
Loading data from data/ultrachat_train.jsonl...
Step 1: Training on batch of 64 examples...
