Initializing Tinker ServiceClient (base_url=https://tinker.thinkingmachines.dev/services/tinker-prod)
âœ“ ServiceClient initialized
Getting server capabilities...
âœ“ Available models: ['deepseek-ai/DeepSeek-V3.1', 'deepseek-ai/DeepSeek-V3.1-Base', 'moonshotai/Kimi-K2-Thinking', 'meta-llama/Llama-3.1-70B', 'meta-llama/Llama-3.1-8B', 'meta-llama/Llama-3.1-8B-Instruct', 'meta-llama/Llama-3.2-1B', 'meta-llama/Llama-3.2-3B', 'meta-llama/Llama-3.3-70B-Instruct', 'Qwen/Qwen3-235B-A22B-Instruct-2507', 'Qwen/Qwen3-30B-A3B', 'Qwen/Qwen3-30B-A3B-Base', 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'Qwen/Qwen3-32B', 'Qwen/Qwen3-4B-Instruct-2507', 'Qwen/Qwen3-8B', 'Qwen/Qwen3-8B-Base', 'Qwen/Qwen3-VL-235B-A22B-Instruct', 'Qwen/Qwen3-VL-30B-A3B-Instruct', 'openai/gpt-oss-120b', 'openai/gpt-oss-20b']
âœ“ Auto-selected base model: Qwen/Qwen3-8B
Creating LoRA training client (rank=16)...
âœ“ Training client created
Getting tokenizer...
âœ“ Tokenizer ready
Loading data from data/ultrachat_train.jsonl...
Step 1: Training on batch of 16 examples...
âœ“ Step 1 complete
Step 2: Training on batch of 16 examples...
âœ“ Step 2 complete
Step 3: Training on batch of 16 examples...
âœ“ Step 3 complete
Step 4: Training on batch of 16 examples...
âœ“ Step 4 complete
Step 5: Training on batch of 16 examples...
âœ“ Step 5 complete
Saving checkpoint: step_0005...
âœ“ Saved: <tinker.lib.public_interfaces.api_future.AwaitableConcurrentFuture object at 0x1118cddd0>
Step 6: Training on batch of 16 examples...
âœ“ Step 6 complete
Step 7: Training on batch of 16 examples...
âœ“ Step 7 complete
Step 8: Training on batch of 16 examples...
âœ“ Step 8 complete
Step 9: Training on batch of 16 examples...
âœ“ Step 9 complete
Step 10: Training on batch of 16 examples...
âœ“ Step 10 complete
Saving checkpoint: step_0010...
âœ“ Saved: <tinker.lib.public_interfaces.api_future.AwaitableConcurrentFuture object at 0x115a0b750>
Reached max_steps=10, stopping
Saving final checkpoint...
âœ“ Saved: <tinker.lib.public_interfaces.api_future.AwaitableConcurrentFuture object at 0x115fa4e50>

âœ… Training complete! Total steps: 10

ðŸ“¦ Saved checkpoints:
   <tinker.lib.public_interfaces.api_future.AwaitableConcurrentFuture object at 0x1118cddd0>
   <tinker.lib.public_interfaces.api_future.AwaitableConcurrentFuture object at 0x115a0b750>
   <tinker.lib.public_interfaces.api_future.AwaitableConcurrentFuture object at 0x115fa4e50>
